{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "217e3b32",
   "metadata": {},
   "source": [
    "**Project Topic**\n",
    "\n",
    "In this project, I implemented Long Short Term Memory (LSTM) to perform Natural Language Processing (NLP) on tweets. My code was trained and validated to detect whether a given tweet is indicative of a natural disaster or not. I experimented with different dropout rates and found I was able to achieve a ~92% accuracy on training data and a ~75% accuracy on testing data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a00e2e9",
   "metadata": {},
   "source": [
    "**Data**\n",
    "\n",
    "First, I important relevant Python libraries and imported the data. The training data has 7613 rows for that number of tweets. The testing data has 3263 rows. I printed some of the columns to get a sense for different variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "id": "7d21c720",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn import feature_extraction, linear_model, model_selection, preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "import random\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow import keras\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from scipy import stats\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Embedding, LSTM, Dropout, Dense\n",
    "from keras.preprocessing.sequence import pad_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "id": "4ebe15fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv(\"nlp-getting-started/train.csv\")\n",
    "val_df = pd.read_csv(\"nlp-getting-started/test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "id": "ffc3c383",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = train_df.drop(columns=['keyword','location'])\n",
    "val_df = val_df.drop(columns=['keyword','location'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63560579",
   "metadata": {},
   "source": [
    "**Exploratory Data Analysis**\n",
    "\n",
    "After visualizing a subset of the data, I looked at to what extent it would need to be cleaned and pre-processed. Since the data set comes from a Kaggle competition, it was already in relatively good condition. There weren't any totally invalid tweets that I just needed to delete entirely.\n",
    "\n",
    "My pre-processing methodology comes directly from Reference 6, which is an example notebook for a different data science application but I found has a good pre-processing algorithm that would be applicable to this natural disaster natural language processing project.\n",
    "\n",
    "To make it easier for the models to digest, I first removed a variety of characters.\n",
    "\n",
    "Next, I split the data into training and testing sets. There is still the separate testing/validation set for the Kaggle submission, but this intermediate testing set derived from the training data helsp with assessing the performance of my model for each training epoch. \n",
    "\n",
    "Finally, I tokenized the text such that it now contains counts for the 4,000 most common words used across all of the tweets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "id": "423e8afe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         id                                               text\n",
      "0         0                 Just happened a terrible car crash\n",
      "1         2  Heard about #earthquake is different cities, s...\n",
      "2         3  there is a forest fire at spot pond, geese are...\n",
      "3         9           Apocalypse lighting. #Spokane #wildfires\n",
      "4        11      Typhoon Soudelor kills 28 in China and Taiwan\n",
      "...     ...                                                ...\n",
      "3258  10861  EARTHQUAKE SAFETY LOS ANGELES ÛÒ SAFETY FASTE...\n",
      "3259  10865  Storm in RI worse than last hurricane. My city...\n",
      "3260  10868  Green Line derailment in Chicago http://t.co/U...\n",
      "3261  10874  MEG issues Hazardous Weather Outlook (HWO) htt...\n",
      "3262  10875  #CityofCalgary has activated its Municipal Eme...\n",
      "\n",
      "[3263 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "print(val_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "id": "ea6a64d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         id                                               text  target\n",
      "0         1  our deeds are the reason of this earthquake ma...       1\n",
      "1         4              forest fire near la ronge sask canada       1\n",
      "2         5  all residents asked to shelter in place are be...       1\n",
      "3         6  13000 people receive wildfires evacuation orde...       1\n",
      "4         7  just got sent this photo from ruby alaska as s...       1\n",
      "...     ...                                                ...     ...\n",
      "7608  10869  two giant cranes holding a bridge collapse int...       1\n",
      "7609  10870  aria ahrary thetawniest the out of control wil...       1\n",
      "7610  10871              m194 0104 utc 5km s of volcano hawaii       1\n",
      "7611  10872  police investigating after an e bike collided ...       1\n",
      "7612  10873  the latest more homes razed by northern califo...       1\n",
      "\n",
      "[7613 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "print(train_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "id": "9ab81f78",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process(x):\n",
    "    x = re.sub('[,\\.!?:()\"]', '', x)\n",
    "    x = re.sub('<.*?>', ' ', x)\n",
    "    x = re.sub('http\\S+', ' ', x)\n",
    "    x = re.sub('[^a-zA-Z0-9]', ' ', x)\n",
    "    x = re.sub('\\s+', ' ', x)\n",
    "    return x.lower().strip()\n",
    "\n",
    "train_df['text'] = train_df['text'].apply(lambda x: process(x))\n",
    "val_df['text'] = val_df['text'].apply(lambda x: process(x))                       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "id": "37cb7f0a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>7613.000000</td>\n",
       "      <td>7613.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>5441.934848</td>\n",
       "      <td>0.42966</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>3137.116090</td>\n",
       "      <td>0.49506</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>2734.000000</td>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>5408.000000</td>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>8146.000000</td>\n",
       "      <td>1.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>10873.000000</td>\n",
       "      <td>1.00000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 id      target\n",
       "count   7613.000000  7613.00000\n",
       "mean    5441.934848     0.42966\n",
       "std     3137.116090     0.49506\n",
       "min        1.000000     0.00000\n",
       "25%     2734.000000     0.00000\n",
       "50%     5408.000000     0.00000\n",
       "75%     8146.000000     1.00000\n",
       "max    10873.000000     1.00000"
      ]
     },
     "execution_count": 189,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "id": "40ab7dc0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'i love fruits'"
      ]
     },
     "execution_count": 190,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df[train_df[\"target\"] == 0][\"text\"].values[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "id": "9f9b07e7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'forest fire near la ronge sask canada'"
      ]
     },
     "execution_count": 191,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df[train_df[\"target\"] == 1][\"text\"].values[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "id": "fb1290c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_rev, test_rev, train_sent, test_sent = train_test_split(train_df['text'], train_df['target'], test_size=0.1, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "id": "6d629cf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_rev = val_df['text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82fa5145",
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_size = 4000\n",
    "tokenizer = Tokenizer(num_words=dict_size)\n",
    "tokenizer.fit_on_texts(train_df['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "id": "34695fef",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_rev_tokens = tokenizer.texts_to_sequences(train_rev)\n",
    "test_rev_tokens = tokenizer.texts_to_sequences(test_rev)\n",
    "seq_lengths =  np.array([len(sequence) for sequence in train_rev_tokens])\n",
    "\n",
    "upper_bound = int(np.mean(seq_lengths) + 2 * np.std(seq_lengths))\n",
    "percentage = stats.percentileofscore(seq_lengths, upper_bound)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "id": "4d14c71b",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_rev_pad = pad_sequences(train_rev_tokens, maxlen=upper_bound)\n",
    "test_rev_pad = pad_sequences(test_rev_tokens, maxlen=upper_bound)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "id": "0d155c02",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "150722\n"
     ]
    }
   ],
   "source": [
    "print(train_rev_pad.size)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b9b25f3",
   "metadata": {},
   "source": [
    "**Model Architecture**\n",
    "\n",
    "I also followed Reference 6 (Kaggle project for a different NLP application) for the model architecture portion of this report. Using Keras/Tensorflow, I implemented LSTM with a variable dropout rate. I was curious how the dropout rate would affect the learning rate as well as the end accuracies on both the training and testing data sets. My hypothesis was that higher dropout rates would reduce overfitting. I built and trained models with dropout rates of 0.6, 0.7, 0.8, and 0.9. I trained all of those models to 20 epochs to make sure I wasn't stopping the training early on any of them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "id": "61c8c19b",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_dim = 14\n",
    "units_lstm = 16\n",
    "r = 0.6\n",
    "\n",
    "model2 = Sequential()\n",
    "model2.add(Embedding(input_dim=dict_size, output_dim=output_dim, input_length=upper_bound))\n",
    "model2.add(LSTM(units_lstm))\n",
    "model2.add(Dropout(r))\n",
    "model2.add(Dense(1, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "id": "469fa511",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "24/24 [==============================] - 14s 423ms/step - loss: 0.6845 - accuracy: 0.5748 - val_loss: 0.6768 - val_accuracy: 0.5593\n",
      "Epoch 2/20\n",
      "24/24 [==============================] - 5s 211ms/step - loss: 0.6617 - accuracy: 0.5771 - val_loss: 0.6518 - val_accuracy: 0.5681\n",
      "Epoch 3/20\n",
      "24/24 [==============================] - 3s 136ms/step - loss: 0.6130 - accuracy: 0.6653 - val_loss: 0.5873 - val_accuracy: 0.6848\n",
      "Epoch 4/20\n",
      "24/24 [==============================] - 3s 118ms/step - loss: 0.5230 - accuracy: 0.7758 - val_loss: 0.5348 - val_accuracy: 0.7748\n",
      "Epoch 5/20\n",
      "24/24 [==============================] - 3s 111ms/step - loss: 0.4624 - accuracy: 0.8181 - val_loss: 0.5088 - val_accuracy: 0.7690\n",
      "Epoch 6/20\n",
      "24/24 [==============================] - 1s 48ms/step - loss: 0.4073 - accuracy: 0.8430 - val_loss: 0.4986 - val_accuracy: 0.7763\n",
      "Epoch 7/20\n",
      "24/24 [==============================] - 1s 45ms/step - loss: 0.3683 - accuracy: 0.8617 - val_loss: 0.5081 - val_accuracy: 0.7763\n",
      "Epoch 8/20\n",
      "24/24 [==============================] - 1s 49ms/step - loss: 0.3445 - accuracy: 0.8713 - val_loss: 0.5153 - val_accuracy: 0.7719\n",
      "Epoch 9/20\n",
      "24/24 [==============================] - 1s 46ms/step - loss: 0.3198 - accuracy: 0.8832 - val_loss: 0.5395 - val_accuracy: 0.7758\n",
      "Epoch 10/20\n",
      "24/24 [==============================] - 1s 52ms/step - loss: 0.3036 - accuracy: 0.8876 - val_loss: 0.5358 - val_accuracy: 0.7724\n",
      "Epoch 11/20\n",
      "24/24 [==============================] - 1s 57ms/step - loss: 0.2934 - accuracy: 0.9024 - val_loss: 0.5649 - val_accuracy: 0.7738\n",
      "Epoch 12/20\n",
      "24/24 [==============================] - 1s 46ms/step - loss: 0.2784 - accuracy: 0.9016 - val_loss: 0.5829 - val_accuracy: 0.7709\n",
      "Epoch 13/20\n",
      "24/24 [==============================] - 1s 53ms/step - loss: 0.2657 - accuracy: 0.9097 - val_loss: 0.5935 - val_accuracy: 0.7690\n",
      "Epoch 14/20\n",
      "24/24 [==============================] - 1s 46ms/step - loss: 0.2517 - accuracy: 0.9135 - val_loss: 0.6209 - val_accuracy: 0.7636\n",
      "Epoch 15/20\n",
      "24/24 [==============================] - 1s 36ms/step - loss: 0.2433 - accuracy: 0.9166 - val_loss: 0.6407 - val_accuracy: 0.7617\n",
      "Epoch 16/20\n",
      "24/24 [==============================] - 1s 35ms/step - loss: 0.2355 - accuracy: 0.9245 - val_loss: 0.6632 - val_accuracy: 0.7626\n",
      "Epoch 17/20\n",
      "24/24 [==============================] - 1s 38ms/step - loss: 0.2249 - accuracy: 0.9228 - val_loss: 0.6928 - val_accuracy: 0.7563\n",
      "Epoch 18/20\n",
      "24/24 [==============================] - 1s 38ms/step - loss: 0.2186 - accuracy: 0.9268 - val_loss: 0.7011 - val_accuracy: 0.7549\n",
      "Epoch 19/20\n",
      "24/24 [==============================] - 1s 52ms/step - loss: 0.2144 - accuracy: 0.9297 - val_loss: 0.7235 - val_accuracy: 0.7515\n",
      "Epoch 20/20\n",
      "24/24 [==============================] - 2s 66ms/step - loss: 0.2059 - accuracy: 0.9324 - val_loss: 0.7424 - val_accuracy: 0.7563\n"
     ]
    }
   ],
   "source": [
    "validation_split = 0.3\n",
    "batch_size = 200\n",
    "epochs = 20\n",
    "\n",
    "model2.compile(optimizer='adam', loss='bce', metrics='accuracy')\n",
    "\n",
    "fitted2 = model2.fit(train_rev_pad, train_sent, validation_split=validation_split,\n",
    "                   batch_size=batch_size, epochs=epochs, shuffle=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "id": "fc586280",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_dim = 14\n",
    "units_lstm = 16\n",
    "r = 0.7\n",
    "\n",
    "model1 = Sequential()\n",
    "model1.add(Embedding(input_dim=dict_size, output_dim=output_dim, input_length=upper_bound))\n",
    "model1.add(LSTM(units_lstm))\n",
    "model1.add(Dropout(r))\n",
    "model1.add(Dense(1, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "id": "63ad603c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "24/24 [==============================] - 13s 384ms/step - loss: 0.6866 - accuracy: 0.5575 - val_loss: 0.6802 - val_accuracy: 0.5593\n",
      "Epoch 2/20\n",
      "24/24 [==============================] - 3s 135ms/step - loss: 0.6696 - accuracy: 0.5752 - val_loss: 0.6635 - val_accuracy: 0.5593\n",
      "Epoch 3/20\n",
      "24/24 [==============================] - 4s 160ms/step - loss: 0.6368 - accuracy: 0.6171 - val_loss: 0.6160 - val_accuracy: 0.6892\n",
      "Epoch 4/20\n",
      "24/24 [==============================] - 3s 128ms/step - loss: 0.5655 - accuracy: 0.7383 - val_loss: 0.5632 - val_accuracy: 0.7719\n",
      "Epoch 5/20\n",
      "24/24 [==============================] - 3s 105ms/step - loss: 0.5033 - accuracy: 0.7998 - val_loss: 0.5362 - val_accuracy: 0.7612\n",
      "Epoch 6/20\n",
      "24/24 [==============================] - 3s 111ms/step - loss: 0.4516 - accuracy: 0.8269 - val_loss: 0.5190 - val_accuracy: 0.7738\n",
      "Epoch 7/20\n",
      "24/24 [==============================] - 2s 73ms/step - loss: 0.4054 - accuracy: 0.8488 - val_loss: 0.5178 - val_accuracy: 0.7724\n",
      "Epoch 8/20\n",
      "24/24 [==============================] - 3s 116ms/step - loss: 0.3805 - accuracy: 0.8571 - val_loss: 0.5075 - val_accuracy: 0.7665\n",
      "Epoch 9/20\n",
      "24/24 [==============================] - 2s 97ms/step - loss: 0.3403 - accuracy: 0.8770 - val_loss: 0.5367 - val_accuracy: 0.7626\n",
      "Epoch 10/20\n",
      "24/24 [==============================] - 3s 130ms/step - loss: 0.3271 - accuracy: 0.8853 - val_loss: 0.5459 - val_accuracy: 0.7539\n",
      "Epoch 11/20\n",
      "24/24 [==============================] - 2s 87ms/step - loss: 0.3083 - accuracy: 0.8972 - val_loss: 0.5848 - val_accuracy: 0.7631\n",
      "Epoch 12/20\n",
      "24/24 [==============================] - 3s 138ms/step - loss: 0.2999 - accuracy: 0.8957 - val_loss: 0.5797 - val_accuracy: 0.7597\n",
      "Epoch 13/20\n",
      "24/24 [==============================] - 3s 110ms/step - loss: 0.2820 - accuracy: 0.9059 - val_loss: 0.6019 - val_accuracy: 0.7612\n",
      "Epoch 14/20\n",
      "24/24 [==============================] - 3s 112ms/step - loss: 0.2654 - accuracy: 0.9097 - val_loss: 0.6316 - val_accuracy: 0.7524\n",
      "Epoch 15/20\n",
      "24/24 [==============================] - 2s 85ms/step - loss: 0.2488 - accuracy: 0.9174 - val_loss: 0.6609 - val_accuracy: 0.7437\n",
      "Epoch 16/20\n",
      "24/24 [==============================] - 2s 95ms/step - loss: 0.2403 - accuracy: 0.9224 - val_loss: 0.6842 - val_accuracy: 0.7471\n",
      "Epoch 17/20\n",
      "24/24 [==============================] - 2s 97ms/step - loss: 0.2274 - accuracy: 0.9241 - val_loss: 0.7024 - val_accuracy: 0.7500\n",
      "Epoch 18/20\n",
      "24/24 [==============================] - 2s 77ms/step - loss: 0.2128 - accuracy: 0.9335 - val_loss: 0.7346 - val_accuracy: 0.7481\n",
      "Epoch 19/20\n",
      "24/24 [==============================] - 2s 86ms/step - loss: 0.2114 - accuracy: 0.9339 - val_loss: 0.7476 - val_accuracy: 0.7466\n",
      "Epoch 20/20\n",
      "24/24 [==============================] - 2s 76ms/step - loss: 0.2057 - accuracy: 0.9370 - val_loss: 0.7708 - val_accuracy: 0.7451\n"
     ]
    }
   ],
   "source": [
    "validation_split = 0.3\n",
    "batch_size = 200\n",
    "epochs = 20\n",
    "\n",
    "model1.compile(optimizer='adam', loss='bce', metrics='accuracy')\n",
    "\n",
    "fitted1 = model1.fit(train_rev_pad, train_sent, validation_split=validation_split,\n",
    "                   batch_size=batch_size, epochs=epochs, shuffle=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "id": "03b9924f",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_dim = 14\n",
    "units_lstm = 16\n",
    "r = 0.9\n",
    "\n",
    "model0 = Sequential()\n",
    "model0.add(Embedding(input_dim=dict_size, output_dim=output_dim, input_length=upper_bound))\n",
    "model0.add(LSTM(units_lstm))\n",
    "model0.add(Dropout(r))\n",
    "model0.add(Dense(1, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "id": "15e3c958",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "24/24 [==============================] - 12s 350ms/step - loss: 0.6890 - accuracy: 0.5572 - val_loss: 0.6847 - val_accuracy: 0.5593\n",
      "Epoch 2/20\n",
      "24/24 [==============================] - 4s 152ms/step - loss: 0.6770 - accuracy: 0.5754 - val_loss: 0.6743 - val_accuracy: 0.5593\n",
      "Epoch 3/20\n",
      "24/24 [==============================] - 3s 141ms/step - loss: 0.6668 - accuracy: 0.5977 - val_loss: 0.6573 - val_accuracy: 0.5978\n",
      "Epoch 4/20\n",
      "24/24 [==============================] - 3s 111ms/step - loss: 0.6360 - accuracy: 0.6425 - val_loss: 0.6183 - val_accuracy: 0.7111\n",
      "Epoch 5/20\n",
      "24/24 [==============================] - 2s 89ms/step - loss: 0.5820 - accuracy: 0.7220 - val_loss: 0.5614 - val_accuracy: 0.7568\n",
      "Epoch 6/20\n",
      "24/24 [==============================] - 3s 118ms/step - loss: 0.5383 - accuracy: 0.7610 - val_loss: 0.5306 - val_accuracy: 0.7665\n",
      "Epoch 7/20\n",
      "24/24 [==============================] - 3s 136ms/step - loss: 0.4959 - accuracy: 0.7800 - val_loss: 0.5063 - val_accuracy: 0.7738\n",
      "Epoch 8/20\n",
      "24/24 [==============================] - 2s 98ms/step - loss: 0.4653 - accuracy: 0.8050 - val_loss: 0.4988 - val_accuracy: 0.7733\n",
      "Epoch 9/20\n",
      "24/24 [==============================] - 3s 142ms/step - loss: 0.4376 - accuracy: 0.8129 - val_loss: 0.4976 - val_accuracy: 0.7680\n",
      "Epoch 10/20\n",
      "24/24 [==============================] - 4s 156ms/step - loss: 0.4212 - accuracy: 0.8133 - val_loss: 0.4965 - val_accuracy: 0.7685\n",
      "Epoch 11/20\n",
      "24/24 [==============================] - 3s 123ms/step - loss: 0.4033 - accuracy: 0.8275 - val_loss: 0.5124 - val_accuracy: 0.7680\n",
      "Epoch 12/20\n",
      "24/24 [==============================] - 2s 88ms/step - loss: 0.3969 - accuracy: 0.8327 - val_loss: 0.5164 - val_accuracy: 0.7626\n",
      "Epoch 13/20\n",
      "24/24 [==============================] - 2s 92ms/step - loss: 0.3777 - accuracy: 0.8321 - val_loss: 0.5200 - val_accuracy: 0.7685\n",
      "Epoch 14/20\n",
      "24/24 [==============================] - 1s 40ms/step - loss: 0.3708 - accuracy: 0.8279 - val_loss: 0.5363 - val_accuracy: 0.7626\n",
      "Epoch 15/20\n",
      "24/24 [==============================] - 1s 45ms/step - loss: 0.3567 - accuracy: 0.8450 - val_loss: 0.5477 - val_accuracy: 0.7602\n",
      "Epoch 16/20\n",
      "24/24 [==============================] - 2s 82ms/step - loss: 0.3526 - accuracy: 0.8444 - val_loss: 0.5468 - val_accuracy: 0.7563\n",
      "Epoch 17/20\n",
      "24/24 [==============================] - 2s 66ms/step - loss: 0.3449 - accuracy: 0.8496 - val_loss: 0.5551 - val_accuracy: 0.7622\n",
      "Epoch 18/20\n",
      "24/24 [==============================] - 3s 129ms/step - loss: 0.3345 - accuracy: 0.8540 - val_loss: 0.5725 - val_accuracy: 0.7544\n",
      "Epoch 19/20\n",
      "24/24 [==============================] - 3s 117ms/step - loss: 0.3315 - accuracy: 0.8621 - val_loss: 0.5915 - val_accuracy: 0.7636\n",
      "Epoch 20/20\n",
      "24/24 [==============================] - 3s 106ms/step - loss: 0.3221 - accuracy: 0.8584 - val_loss: 0.6482 - val_accuracy: 0.7359\n"
     ]
    }
   ],
   "source": [
    "validation_split = 0.3\n",
    "batch_size = 200\n",
    "epochs = 20\n",
    "\n",
    "model0.compile(optimizer='adam', loss='bce', metrics='accuracy')\n",
    "\n",
    "fitted0 = model0.fit(train_rev_pad, train_sent, validation_split=validation_split,\n",
    "                   batch_size=batch_size, epochs=epochs, shuffle=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "id": "6e561c6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_dim = 14\n",
    "units_lstm = 16\n",
    "r = 0.8\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Embedding(input_dim=dict_size, output_dim=output_dim, input_length=upper_bound))\n",
    "model.add(LSTM(units_lstm))\n",
    "model.add(Dropout(r))\n",
    "model.add(Dense(1, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "id": "47925179",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_12\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_12 (Embedding)    (None, 22, 14)            28000     \n",
      "                                                                 \n",
      " lstm_12 (LSTM)              (None, 16)                1984      \n",
      "                                                                 \n",
      " dropout_12 (Dropout)        (None, 16)                0         \n",
      "                                                                 \n",
      " dense_12 (Dense)            (None, 1)                 17        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 30001 (117.19 KB)\n",
      "Trainable params: 30001 (117.19 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "id": "3043feba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "24/24 [==============================] - 19s 371ms/step - loss: 0.3906 - accuracy: 0.8442 - val_loss: 0.5038 - val_accuracy: 0.7797\n",
      "Epoch 2/20\n",
      "24/24 [==============================] - 3s 123ms/step - loss: 0.3719 - accuracy: 0.8567 - val_loss: 0.5100 - val_accuracy: 0.7772\n",
      "Epoch 3/20\n",
      "24/24 [==============================] - 2s 97ms/step - loss: 0.3536 - accuracy: 0.8680 - val_loss: 0.5260 - val_accuracy: 0.7738\n",
      "Epoch 4/20\n",
      "24/24 [==============================] - 3s 106ms/step - loss: 0.3411 - accuracy: 0.8690 - val_loss: 0.5319 - val_accuracy: 0.7665\n",
      "Epoch 5/20\n",
      "24/24 [==============================] - 2s 95ms/step - loss: 0.3342 - accuracy: 0.8767 - val_loss: 0.5404 - val_accuracy: 0.7568\n",
      "Epoch 6/20\n",
      "24/24 [==============================] - 3s 111ms/step - loss: 0.3201 - accuracy: 0.8824 - val_loss: 0.5440 - val_accuracy: 0.7695\n",
      "Epoch 7/20\n",
      "24/24 [==============================] - 2s 100ms/step - loss: 0.3106 - accuracy: 0.8868 - val_loss: 0.5523 - val_accuracy: 0.7656\n",
      "Epoch 8/20\n",
      "24/24 [==============================] - 2s 104ms/step - loss: 0.2983 - accuracy: 0.8893 - val_loss: 0.5680 - val_accuracy: 0.7685\n",
      "Epoch 9/20\n",
      "24/24 [==============================] - 2s 80ms/step - loss: 0.2946 - accuracy: 0.8970 - val_loss: 0.5937 - val_accuracy: 0.7481\n",
      "Epoch 10/20\n",
      "24/24 [==============================] - 2s 99ms/step - loss: 0.2815 - accuracy: 0.8947 - val_loss: 0.5934 - val_accuracy: 0.7534\n",
      "Epoch 11/20\n",
      "24/24 [==============================] - 2s 78ms/step - loss: 0.2774 - accuracy: 0.8997 - val_loss: 0.6106 - val_accuracy: 0.7636\n",
      "Epoch 12/20\n",
      "24/24 [==============================] - 2s 83ms/step - loss: 0.2654 - accuracy: 0.9030 - val_loss: 0.6468 - val_accuracy: 0.7544\n",
      "Epoch 13/20\n",
      "24/24 [==============================] - 2s 80ms/step - loss: 0.2609 - accuracy: 0.9091 - val_loss: 0.6465 - val_accuracy: 0.7524\n",
      "Epoch 14/20\n",
      "24/24 [==============================] - 2s 83ms/step - loss: 0.2515 - accuracy: 0.9089 - val_loss: 0.6784 - val_accuracy: 0.7554\n",
      "Epoch 15/20\n",
      "24/24 [==============================] - 2s 87ms/step - loss: 0.2467 - accuracy: 0.9109 - val_loss: 0.6963 - val_accuracy: 0.7442\n",
      "Epoch 16/20\n",
      "24/24 [==============================] - 2s 84ms/step - loss: 0.2493 - accuracy: 0.9049 - val_loss: 0.6711 - val_accuracy: 0.7519\n",
      "Epoch 17/20\n",
      "24/24 [==============================] - 2s 79ms/step - loss: 0.2341 - accuracy: 0.9143 - val_loss: 0.7321 - val_accuracy: 0.7534\n",
      "Epoch 18/20\n",
      "24/24 [==============================] - 2s 78ms/step - loss: 0.2279 - accuracy: 0.9139 - val_loss: 0.7264 - val_accuracy: 0.7505\n",
      "Epoch 19/20\n",
      "24/24 [==============================] - 2s 85ms/step - loss: 0.2246 - accuracy: 0.9197 - val_loss: 0.7479 - val_accuracy: 0.7369\n",
      "Epoch 20/20\n",
      "24/24 [==============================] - 2s 100ms/step - loss: 0.2162 - accuracy: 0.9226 - val_loss: 0.7761 - val_accuracy: 0.7534\n"
     ]
    }
   ],
   "source": [
    "validation_split = 0.3\n",
    "batch_size = 200\n",
    "epochs = 20\n",
    "\n",
    "model.compile(optimizer='adam', loss='bce', metrics='accuracy')\n",
    "\n",
    "fitted = model.fit(train_rev_pad, train_sent, validation_split=validation_split,\n",
    "                   batch_size=batch_size, epochs=epochs, shuffle=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67e844cb",
   "metadata": {},
   "source": [
    "**Results and Analysis**\n",
    "\n",
    "The highest dropout rate of 0.9 performed the worst. The other three dropout rates yielded similar results: accuracy on the order of 92% and validation accuracy on the order of 75%. I picked the model with the dropout rate of 0.8 as the one I would use to perform the predictions for the Kaggle competition because in the event that the extent of overfitting may not have been captured by the 20 epochs of training with validation, I thought that the higher dropout rate would give me the best result in with the competition data set.\n",
    "\n",
    "I created a confusion matrix to better visualize the performance of my model and see if it was biased in any way. Overall, I deemed the results to be relatively well balanced. While there were more true non-disasters than actual disaster, the number of incorrect predicitons in either case were very close - 103 vs. 97. This indicates to me that the model isn't defaulting to automatically picking the more common outcome.\n",
    "\n",
    "Finally, I used the model.predict() function to perfor my predictons on the Kaggle data set. After uploading to the Kaggle website, I found that scored an accuracy of 76.8%, putting me in 902nd place."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ff1e468",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_pred =  model.evaluate(test_rev_pad, test_sent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "id": "025ade86",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24/24 [==============================] - 1s 29ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<sklearn.metrics._plot.confusion_matrix.ConfusionMatrixDisplay at 0x48935f0d0>"
      ]
     },
     "execution_count": 242,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAATgAAAEGCAYAAADxD4m3AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8pXeV/AAAACXBIWXMAAAsTAAALEwEAmpwYAAAatUlEQVR4nO3de5RddX338fdnJpP7xYRcDEmQWwQBIWJEkEdE1CcEbYNWbZRab12ABVFLteDTpVaLrVVqKVeDsuCxQBoKKiqCkAdEKhhCCgiBSCBchsTc75fJzJnv88feEw7JzJm9zZw55+z5vNbaK2f/9u17Zpgvv8vev62IwMysiJpqHYCZWbU4wZlZYTnBmVlhOcGZWWE5wZlZYQ2qdQDlxo9rjoOntdQ6DMvhmd+NqHUIlsPO2M7u2KX9Ocesd46I9RtKmfZ95PG2uyLi9P253v6oqwR38LQWFt01rdZhWA6zDz2x1iFYDg/tumO/z7FuQ4nf3jU1074tk58dv98X3A91leDMrBEEpeisdRCZOMGZWS4BdNIYDwg4wZlZbp24BmdmBRQE7W6imlkRBVByE9XMisp9cGZWSAGUGmQWIic4M8utMXrgnODMLKcg3AdnZsUUAe2Nkd+c4MwsL1Fivx5n7TdOcGaWSwCdrsGZWVG5BmdmhZTc6OsEZ2YFFEB7NMZcuU5wZpZLIEoNMhm4E5yZ5dYZjdFEbYw0bGZ1o6sPLstSiaShkhZJekzSk5L+IS0fJ+luSc+k/44tO+ZiScslLZM0q7dYneDMLCdRiqZMSy/agNMi4jhgBnC6pBOBi4CFETEdWJiuI+koYC5wNHA6cJWk5koXcIIzs1ySGX2bMi0Vz5PYlq62pEsAc4Ab0vIbgDPTz3OA+RHRFhErgOXACZWu4T44M8slQuyOihWncuMlLS5bnxcR87pW0hrYI8DhwJUR8VtJkyJiVXKtWCVpYrr7FOChsnO1pmU9coIzs9w6s98Hty4iZva0MSJKwAxJrwF+JOmYCufq7qIVn6lwgjOzXJJBhr7t3YqITZLuI+lbWy1pclp7mwysSXdrBcrfKzoVWFnpvO6DM7Oc+maQQdKEtOaGpGHAu4GngduBj6e7fRz4Sfr5dmCupCGSDgGmA4sqXcM1ODPLpWuQoQ9MBm5I++GagAUR8TNJDwILJH0aeBH4EEBEPClpAbAU6ADOS5u4PXKCM7PcSn1wo29EPA68qZvy9cC7ejjmEuCSrNdwgjOzXALRHo2ROhojSjOrG9UYZKgWJzgzyyVQnzRR+4MTnJnl1keDDFXnBGdmuUSQ5TnTuuAEZ2a5JIMMmR/VqiknODPLzYMMZlZIgRpmwksnODPLzTU4Myuk5L2oTnBmVkh+s72ZFVTy2kCPoppZAUXITVQzKy7f6GtmhZTMB+c+ODMrJLkGZ2bFlNwm4hqcmRWQn0U1s0LzdElmVkjJdEluoppZQbkPzswKKZlNxE1UMyug5FEtJ7gBYfcuceEHDqd9dxOlDnj7ezfzl1/8A9d+/UAeuns0LYODya9r48LvvsTIMSWe/p/hXPbFaUDyH8rHLvwDJ8/eXNsvMcB84VvPccI7N7JpfQufmX0sACPHdHDx5c8waWobq1uH8E/nT2fblkG8/thtXPDNFQBIcONlU/jNL8fVMvw60Dg1uKpGKel0ScskLZd0UTWvVSstQ4J/ueVZrrlnGVffvYzF943iqUeGc/wpW5l379Ncs3AZUw5tY/7lEwE4+IidXHHnMq6+ZxmX3Pgsl31pKqWOGn+JAebu/xrP33/yyFeVffjclTz6mzH81WkzePQ3Y/jwZ1YC8MLvh3HBnGM4/31v5O8/cQSf/ccVNDVHLcKuK50o01JrVUtwkpqBK4HZwFHARyQdVa3r1YoEw0Z0AtDRLkrtQoI3n7qV5rR+/IY372DdqhYAhg6PPeXtbU2o9v8NDDhPPDyarZte3Xg56T0buefW8QDcc+t4TnrPRgDadjXTWUp+SYOHdOLU9sooapal1qrZRD0BWB4RzwFImg/MAZZW8Zo1USrB+bOOYOXzg/mTT6zjyON3vGr7XTeP4x1zNu1Zf3rJcC79m2msaR3Mly5/cU/Cs9p5zfh2Nq4dDMDGtYMZc0D7nm1HHLeNL3zrOSZOaeM7Fx62J+ENZG6iwhTgpbL11rTsVSSdLWmxpMVr15eqGE71NDfD1fcs48ZHlrLs0eE8//TQPdtuumwSzYOC0z6wcU/Zkcfv4Nr7lnH5L37P/MsnsnuX/2Dq2bLHRnLu6cfyuTOP4cOfWUnL4M5ah1RTXe9kyLLUWjUTXHffbp8afkTMi4iZETFzwgGN8fhHT0aOKXHcSdt4+N5RANy9YCyL7hnN313xQrdN0YOmtzF0eCfPLxu670brV5vWtTB2wm4Axk7Yzeb1Lfvs89Kzw9i1o4mDj9ixz7aBJICOaMq01Fo1I2gFppWtTwVWVvF6NbFpfTPbNieJuW2nWPLrUUw7vI2H7x3Fgisn8bXrn2Po8Ffy+h9eHLxnUGF1awutzw5l0tTdtQjdyjx0z1je/WfrAHj3n63jwbvHAjBp6q49gwoTD2xj6qG7WN06pGZx1ovOaMq01Fo1e38eBqZLOgR4GZgLfLSK16uJDatb+M7nDqKzU3R2wil/sokT37OFT7ztDbS3iYv//HAAjnzzdj73rVaeWDSC/7ziEAYNgqam4LPfbGXMAY3ZNG9Uf3fZco596xZGj+3gh/+9hB9eNpUF10zmy1csZ9aH17B25RAuOW86AEfP3MqHz/09HR0iOuHKrxzMlo371u4GlDppfmahiOqNC0k6A/g3oBm4LiIuqbT/zOOGxqK7plXaxerM7ENPrHUIlsNDu+5gc+f6/cpOY4+cGKdd98FM+9528tWPRMTM/bne/qjq+F1E3AHcUc1rmFn/a5QanG9QMLNcPOGlmRVWIDo6az+AkIUTnJnlVg+PYWXhBGdm+YSbqGZWUO6DM7NCa5QE1xg9hWZWNwJR6mzKtFQiaZqkeyU9JelJSZ9Ly78m6WVJj6bLGWXHXJxOv7ZM0qzeYnUNzsxy66NBhg7gwohYImkU8Iiku9Nt342I75TvnE63Nhc4GjgQuEfS6yOix0eBnODMLJfoo0GGiFgFrEo/b5X0FN3MOFRmDjA/ItqAFZKWk0zL9mBPB7iJama5RSjTkpWkg4E3Ab9Ni86X9Lik6ySNTcsyTcFWzgnOzHLKNR/c+K75HtPl7H3OJo0EbgU+HxFbgKuBw4AZJDW8S/dceF8VH6Z3E9XMcstRO1tX6WF7SS0kye3GiLgtOXesLtt+LfCzdDX3FGyuwZlZLhFQ6lSmpRJJAn4APBUR/1pWPrlst/cDT6SfbwfmShqSTsM2HVhU6RquwZlZbn00inoy8DHgd5IeTcu+TPKCqhkkzc/ngXMAIuJJSQtI3uvSAZxXaQQVnODMLKcgVxO15/NEPED3/Wo9TrGWzilZcV7Jck5wZpZT48zo6wRnZrlVcSLwPuUEZ2a59UUTtT84wZlZLskoamPcgOEEZ2a5uYlqZoXlJqqZFVKQ7znTWnKCM7PcGqSF6gRnZjkFRC+PYdULJzgzy81NVDMrrIYfRZV0ORWa2hFxQVUiMrO61lfPovaHSjW4xf0WhZk1jgAaPcFFxA3l65JGRMT26odkZvWuUZqovT5vIekkSUuBp9L14yRdVfXIzKxOiejMttRalgfK/g2YBawHiIjHgFOqGJOZ1bvIuNRYplHUiHgpmV14j4qzaJpZgUUxBhm6vCTpbUBIGgxcQNpcNbMBqg5qZ1lkaaKeC5xH8v7Bl0le5XVeFWMys7qnjEtt9VqDi4h1wFn9EIuZNYrOWgeQTZZR1EMl/VTSWklrJP1E0qH9EZyZ1aGu++CyLDWWpYl6E7AAmAwcCNwC3FzNoMysvkVkW2otS4JTRPwwIjrS5T9omC5GM6uKRr9NRNK49OO9ki4C5pOE/OfAz/shNjOrV3XQ/Myi0iDDIyQJreubnFO2LYBvVCsoM6tvqoPaWRaVnkU9pD8DMbMGEYI6eAwri0xPMkg6BjgKGNpVFhH/t1pBmVmda/QaXBdJXwVOJUlwdwCzgQcAJzizgapBElyWUdQPAu8C/hARnwSOA4ZUNSozq2+NPopaZmdEdErqkDQaWAP4Rl+zgaoIE16WWSzpNcC1JCOr24BF1QzKzOpbw4+idomIv04/XiPpTmB0RDxe3bDMrK41eoKTdHylbRGxpDohmVm9K0IN7tIK2wI4rY9j4fePD2fWgTP6+rRWRa23HlbrECyH3V/so/HBRu+Di4h39mcgZtYg6mSENAu/+NnM8nOCM7OiUoNMeOkEZ2b5NUgNLsuMvpL0F5K+kq4fJOmE6odmZvVIkX2ptSyPal0FnAR8JF3fClxZtYjMrP4VaMryt0bEecAugIjYCAyualRmVt/64FlUSdMk3SvpKUlPSvpcWj5O0t2Snkn/HVt2zMWSlktaJmlWb2FmSXDtkpq7wpU0gYZ5p46ZVUMfNVE7gAsj4g3AicB5ko4CLgIWRsR0YGG6TrptLnA0cDpwVZqbepQlwf078CNgoqRLSKZK+maG48ysiCIZRc2yVDxNxKquJ6IiYivJC+WnAHOAG9LdbgDOTD/PAeZHRFtErACWAxXHA7I8i3qjpEdIpkwScGZE+M32ZgNZ9gGE8ZIWl63Pi4h5e+8k6WDgTcBvgUkRsQqSJChpYrrbFOChssNa07IeZZnw8iBgB/DT8rKIeLG3Y82soLInuHURMbPSDpJGArcCn4+ILVKPgxPdbagYSZb74H7OKy+fGQocAiwjaQeb2QDUV7eASGohSW43RsRtafFqSZPT2ttkkjkoIamxTSs7fCqwstL5e+2Di4g3RsSx6b/TSdq8D+T9ImZm5ZRU1X4APBUR/1q26Xbg4+nnjwM/KSufK2mIpEOA6fQyN2XuJxkiYomkt+Q9zswKpG9qcCcDHwN+J+nRtOzLwD8DCyR9GngR+BBARDwpaQGwlGQE9ryIKFW6QJY+uL8pW20CjgfW5vseZlYY0TfPokbEA3TfrwbJoGZ3x1wCXJL1GllqcKPKPneQ9MndmvUCZlZAdfAYVhYVE1x6E93IiPhiP8VjZnVO1MdzpllUmrJ8UER0VJq63MwGqEZPcCSjE8cDj0q6HbgF2N61sWxI18wGkjqZKSSLLH1w44D1JO9g6LofLgAnOLOBqkGeRq+U4CamI6hP8Epi69Ig+dvMqqEINbhmYCR/xOMRZlZwDZIBKiW4VRHx9X6LxMwaQ0HeqlX76TjNrC4VoYna7Z3EZmYNX4OLiA39GYiZNQ6/NtDMiqkgfXBmZvsQjdNB7wRnZvm5BmdmRVWEUVQzs+45wZlZIfXRhJf9wQnOzPJzDc7Misp9cGZWXE5wZlZUrsGZWTEFhZjw0sxsH4V46YyZWY+c4MysqBSNkeGc4MwsH88mYmZF5j44MyssP6plZsXlGpyZFVLB3mxvZvZqTnBmVkS+0dfMCk2djZHhnODMLB/fBzdwnfnptcw+awNS8IsbD+BH35/Al695nqmHtQEwYnSJ7Vua+ev3HFHjSAeu5nXtjP33Vpo3dYDE9veMZdv7DmD0zasZumgrNInOMc1sOH8KneNaoL2Tsd9bxeBndxKCzZ+aTNsxI2r9NWpqwN8mIuk64H3Amog4plrXqSevO2Ins8/awAXvnU77bvHNm57jtwtH881zD96zz9lfWcn2rU21C9KIZtj8idfSfugwtLPExC8+x67jRrB1zni2fGQSACN/vp7Rt6xl0zkHMuKejQCs/u7hNG3uYPw/vsCabx0KTY3y8rwqaJAaXDX/0q4HTq/i+evOQdPbeGrJcNp2NtFZEo8/OJKTZ28u2yM45U83ce+Px9YsRoPOsS20HzoMgBjWTMfUITRv6CCGN+/ZR22vVFFaWttoe2NSY+scM4jOEc20PLuzf4OuM4psS61VLcFFxP3Ahmqdvx49//RQ3vjWbYwa28GQYZ285bQtTDhw957tx7x1OxvXDmLliiE1jNLKNa/ZTcuKXeyeniS80Teu5rVnL2P4/ZvZMnciAO2vG8rQh7dCKWhevZvBz+5k0LqOWoZdWwFEZFtqrOZ9cJLOBs4GGMrwGkezf15aPpQFV03kn+Y/x67tTaxYOoxSxyvNmHeeuYn7fvya2gVor6KdJQ749kts+uRr99Tetpw1iS1nTWLUbWsZ+YsNbJk7ke3vGsugl9uY+KXnKE1ooe2I4URzLycvuEbpg6t5Z1BEzIuImRExs4XGr9ncdfMBnD/r9fztBw5n66ZmXk5ra03NwclnbOZXt7+mtgFaoiM44NsvsePtY9h14uh9Nu/4X2MY9tCWZKVZbP7kZNZcehjrLzqIph0lOiYP7ueA60fXfXB90USVdJ2kNZKeKCv7mqSXJT2aLmeUbbtY0nJJyyTN6u38NU9wRTPmgHYAJkzZzclnbN5TYzv+7Vt5afkQ1q0auH8YdSOCsVe9TPvUIWz70/F7igetbNvzeejirbRPSf7npLZOtCupsgx5bBs0iY5pQ/s35nqStXmarYl6Pd331X83Imakyx0Ako4C5gJHp8dcJaliXbrmTdSi+cr3X2DU2A5K7eKKL09h2+bkR/yOOW6e1ovBT+9gxK82s/ugIUy88FkAtnx0IsMXbqRl5W5CUJrQwsZzDgRIRk6/8QIISuNa2HDBlFqGXxf6agAhIu6XdHDG3ecA8yOiDVghaTlwAvBgTwdU8zaRm4FTgfGSWoGvRsQPqnW9enHh+w/vtvzSLxzUz5FYT3a/YQSttx69T/muN4/qdv/SxMGsvnx6tcNqLNkT3HhJi8vW50XEvAzHnS/pL4HFwIURsRGYAjxUtk9rWtajqiW4iPhItc5tZrWVowa3LiJm5jz91cA3SNLoN4BLgU+RdP/trWIkbqKaWT4BlKp3C0hErO76LOla4GfpaiswrWzXqcDKSufyIIOZ5VbNG30lTS5bfT/QNcJ6OzBX0hBJhwDTgUWVzuUanJnl10c38XbXVw+cKmkGSV3xeeCc5JLxpKQFwFKgAzgvIkqVzu8EZ2a59eEoand99T0ORkbEJcAlWc/vBGdm+Xi6JDMrKgGq4iBDX3KCM7Pc/GZ7MysmN1HNrLjqYyqkLJzgzCy3epjMMgsnODPLzzU4Myuk8CiqmRVZY+Q3Jzgzy8+3iZhZcTnBmVkhBdAgL51xgjOzXES4iWpmBdbZGFU4Jzgzy8dNVDMrMjdRzay4nODMrJj8sL2ZFVWV36rVl5zgzCw398GZWXE5wZlZIQXQ6QRnZoXkQQYzKzInODMrpABKjfEogxOcmeUUEE5wZlZUbqKaWSF5FNXMCs01ODMrLCc4MyukCCiVah1FJk5wZpafa3BmVlhOcGZWTOFRVDMrqIDwjb5mVlh+VMvMCinCrw00swLzIIOZFVU0SA2uqdYBmFmjSSe8zLL0QtJ1ktZIeqKsbJykuyU9k/47tmzbxZKWS1omaVZv53eCM7N8uh62z7L07nrg9L3KLgIWRsR0YGG6jqSjgLnA0ekxV0lqrnRyJzgzyyWAKJUyLb2eK+J+YMNexXOAG9LPNwBnlpXPj4i2iFgBLAdOqHR+98GZWT6Ra8LL8ZIWl63Pi4h5vRwzKSJWJZeKVZImpuVTgIfK9mtNy3rkBGdmuUX2JxnWRcTMPrqsugul0gFuoppZftGZbfnjrJY0GSD9d01a3gpMK9tvKrCy0okUdXQ/i6S1wAu1jqMKxgPrah2E5VLU39nrImLC/pxA0p0kP58s1kXE3oMIe5/vYOBnEXFMuv5tYH1E/LOki4BxEfElSUcDN5H0ux1IMgAxPSJ67OyrqwRXVJIW92E13fqBf2f9Q9LNwKkkCXM18FXgx8AC4CDgReBDEbEh3f//AJ8COoDPR8QvKp7fCa76/MfSePw7Kwb3wZlZYTnB9Y/ehsWt/vh3VgBuoppZYbkGZ2aF5QRnZoXlBFdFkk5PZz1Ynt7PY3Wuu9ktrHE5wVVJOsvBlcBs4CjgI+lsCFbfrmff2S2sQTnBVc8JwPKIeC4idgPzSWZDsDrWw+wW1qCc4KpnCvBS2XqvMx+YWd9ygque3DMfmFnfcoKrntwzH5hZ33KCq56HgemSDpE0mGSq5dtrHJPZgOIEVyUR0QGcD9wFPAUsiIgnaxuV9Sad3eJB4AhJrZI+XeuY7I/nR7XMrLBcgzOzwnKCM7PCcoIzs8JygjOzwnKCM7PCcoJrIJJKkh6V9ISkWyQN349zXS/pg+nn71eaCEDSqZLe9kdc43lJ+7x9qafyvfbZlvNaX5P0t3ljtGJzgmssOyNiRvp6td3AueUb0xlMcouIv4qIpRV2ORXIneDMas0JrnH9Gjg8rV3dK+km4HeSmiV9W9LDkh6XdA6AEldIWirp58DErhNJuk/SzPTz6ZKWSHpM0sL0nZXnAl9Ia49vlzRB0q3pNR6WdHJ67AGSfinpfyR9j+6fx30VST+W9IikJyWdvde2S9NYFkqakJYdJunO9JhfSzqyT36aVkiDah2A5SdpEMk8c3emRScAx0TEijRJbI6It0gaAvy3pF8CbwKOAN4ITAKWAtftdd4JwLXAKem5xkXEBknXANsi4jvpfjcB342IByQdRPK0xhtI3mn5QER8XdJ7gVclrB58Kr3GMOBhSbdGxHpgBLAkIi6U9JX03OeTvAzm3Ih4RtJbgauA0/6IH6MNAE5wjWWYpEfTz78GfkDSdFwUESvS8v8NHNvVvwaMAaYDpwA3p28BXynp/3Vz/hOB+7vO1fWy3W68GzhK2lNBGy1pVHqND6TH/lzSxgzf6QJJ708/T0tjXQ90Av+Zlv8HcJukken3vaXs2kMyXMMGKCe4xrIzImaUF6R/6NvLi4DPRsRde+13Br1P16QM+0DStXFSROzsJpbMz/5JOpUkWZ4UETsk3QcM7WH3SK+7ae+fgVlP3AdXPHcBn5HUAiDp9ZJGAPcDc9M+usnAO7s59kHgHZIOSY8dl5ZvBUaV7fdLkuYi6X4z0o/3A2elZbOBsb3EOgbYmCa3I0lqkF2agK5a6EdJmr5bgBWSPpReQ5KO6+UaNoA5wRXP90n615akL075HklN/UfAM8DvgKuBX+19YESsJek3u03SY7zSRPwp8P6uQQbgAmBmOoixlFdGc/8BOEXSEpKm8ou9xHonMEjS48A3gIfKtm0Hjpb0CEkf29fT8rOAT6fxPYmngbcKPJuImRWWa3BmVlhOcGZWWE5wZlZYTnBmVlhOcGZWWE5wZlZYTnBmVlj/H2aOTdH5VkZAAAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "predictions = np.round(model.predict(test_rev_pad))\n",
    "cf_matrix = confusion_matrix(test_sent, predictions)\n",
    "\n",
    "\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cf_matrix)\n",
    "disp.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68dc3bc2",
   "metadata": {},
   "source": [
    "In this section, do all the same pre-processing steps to the validation data that will be used to perform predictions on the Kaggle competition data set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "id": "b3cd638a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0                      just happened a terrible car crash\n",
      "1       heard about earthquake is different cities sta...\n",
      "2       there is a forest fire at spot pond geese are ...\n",
      "3                   apocalypse lighting spokane wildfires\n",
      "4           typhoon soudelor kills 28 in china and taiwan\n",
      "                              ...                        \n",
      "3258    earthquake safety los angeles safety fasteners...\n",
      "3259    storm in ri worse than last hurricane my city ...\n",
      "3260                     green line derailment in chicago\n",
      "3261             meg issues hazardous weather outlook hwo\n",
      "3262    cityofcalgary has activated its municipal emer...\n",
      "Name: text, Length: 3263, dtype: object\n",
      "3263\n",
      "71786\n"
     ]
    }
   ],
   "source": [
    "val_df['text'] = val_df['text'].apply(lambda x: process(x))\n",
    "\n",
    "val_rev = val_df['text']\n",
    "print(val_rev)\n",
    "print(val_rev.size)\n",
    "\n",
    "val_rev_tokens = tokenizer.texts_to_sequences(val_rev)\n",
    "\n",
    "val_rev_pad = pad_sequences(val_rev_tokens, maxlen=upper_bound)\n",
    "print(val_rev_pad.size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "id": "356bb1e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "102/102 [==============================] - 1s 8ms/step\n",
      "3263\n",
      "[[0.0900268 ]\n",
      " [0.943518  ]\n",
      " [0.99533635]\n",
      " ...\n",
      " [0.9827639 ]\n",
      " [0.8832012 ]\n",
      " [0.91683143]]\n"
     ]
    }
   ],
   "source": [
    "predictions = model.predict(val_rev_pad)\n",
    "print(len(predictions))\n",
    "print(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "id": "3fccb859",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3263\n",
      "[[0.]\n",
      " [1.]\n",
      " [1.]\n",
      " ...\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]]\n"
     ]
    }
   ],
   "source": [
    "#the predict_generator output is a list of lists, where the elements are the probabilities of each class. \n",
    "#This code turns it into a final predction value by rounding (0 or 1 since there are two classificaiton categories, \n",
    "#then writes it to a csv that I upload to Kaggle\n",
    "pc = np.round_(predictions,decimals=0)\n",
    "print(pc.size)\n",
    "print(pc)\n",
    "pc = pd.DataFrame(pc)\n",
    "pc.to_csv('submission.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abfc8afe",
   "metadata": {},
   "source": [
    " **Conclusion**\n",
    " \n",
    "In this project, I implemented LSTM to classify whether tweets are or are not indicative of a natural disaster. This kind of project could be useful for emergency response authorities and NGOs to determine where to allocate resources and what to respond to real-time.\n",
    "\n",
    "I experimented with modifying the dropout rate in hyperparameter tuning. I found that a dropout rate as high as 0.9 significantly impacted accuracy, but rates ranging from 0.6 to 0.8 yielded similar outcomes after 20 epochs of training.\n",
    "\n",
    "For the Kaggle competition, I was able to achieve a 76.8% accuarcy. This put me in the middle of the pack. If I were to continue this project and try to improve my score, I would experiment with models that contain multiple layers and different activation functions."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1beb4473",
   "metadata": {},
   "source": [
    "**References:**\n",
    "- https://www.kaggle.com/code/philculliton/nlp-getting-started-tutorial/notebook\n",
    "-- This is an example notebook for this project. I used an entirely different ML algorithm for the actual training, but used the example code for importing in the data\n",
    "- https://keras.io/examples/nlp/multi_label_classification/\n",
    "- https://github.com/keras-team/keras/blob/master/keras/datasets/imdb.py\n",
    "- https://stackoverflow.com/questions/49146529/how-keras-imdb-dataset-data-is-preprocessed#:~:text=The%20words%20in%20the%20imdb,it%20will%20download%20the%20dataset.&text=numpy%20arrays%20x_train%2C%20y_train%2C%20x_test,returned%20by%20the%20load_data%20function.\n",
    "- https://keras.io/examples/nlp/bidirectional_lstm_imdb/\n",
    "- https://www.kaggle.com/code/rafaeltiedra/step-by-step-imdb-sentiment-analysis\n",
    "-- This is an example notebook for a different project, but since it was also NLP, I followed many of the methods as well as made my own additions/changes\n",
    "- https://scikit-learn.org/stable/modules/generated/sklearn.metrics.ConfusionMatrixDisplay.html\n",
    "- https://datascience.stackexchange.com/questions/32194/how-to-predict-class-label-from-class-probability-given-by-predict-generator-for\n",
    "- https://keras.io/api/layers/regularization_layers/dropout/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7aca8249",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
